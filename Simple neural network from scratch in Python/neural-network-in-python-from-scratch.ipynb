{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# We are going to implement a simple neural network of one layer in python from scratch. We will not use tensorflow to build the model","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:33:44.341354Z","iopub.execute_input":"2021-05-21T14:33:44.341791Z","iopub.status.idle":"2021-05-21T14:33:44.346698Z","shell.execute_reply.started":"2021-05-21T14:33:44.341743Z","shell.execute_reply":"2021-05-21T14:33:44.345321Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/dataset/insurance_data.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:33:45.319670Z","iopub.execute_input":"2021-05-21T14:33:45.320146Z","iopub.status.idle":"2021-05-21T14:33:45.340166Z","shell.execute_reply.started":"2021-05-21T14:33:45.320107Z","shell.execute_reply":"2021-05-21T14:33:45.338895Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df[['age','affordibility']],df.bought_insurance, test_size=0.2, random_state=28)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:33:46.186479Z","iopub.execute_input":"2021-05-21T14:33:46.186822Z","iopub.status.idle":"2021-05-21T14:33:47.237205Z","shell.execute_reply.started":"2021-05-21T14:33:46.186793Z","shell.execute_reply":"2021-05-21T14:33:47.236217Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X_train_scaled = X_train.copy()\nX_train_scaled['age'] = X_train_scaled['age']/100\n\nX_test_scaled = X_train.copy()\nX_test_scaled['age'] = X_test_scaled['age']/100","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:33:48.229171Z","iopub.execute_input":"2021-05-21T14:33:48.232739Z","iopub.status.idle":"2021-05-21T14:33:48.262995Z","shell.execute_reply.started":"2021-05-21T14:33:48.232659Z","shell.execute_reply":"2021-05-21T14:33:48.260158Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X_test_scaled","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:33:49.437674Z","iopub.execute_input":"2021-05-21T14:33:49.438136Z","iopub.status.idle":"2021-05-21T14:33:49.461144Z","shell.execute_reply.started":"2021-05-21T14:33:49.438092Z","shell.execute_reply":"2021-05-21T14:33:49.459949Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     age  affordibility\n16  0.25              0\n17  0.58              1\n6   0.55              0\n27  0.46              1\n7   0.60              0\n14  0.49              1\n11  0.28              1\n2   0.47              1\n15  0.55              1\n8   0.62              1\n26  0.23              1\n18  0.19              0\n23  0.45              1\n24  0.50              1\n12  0.27              0\n3   0.52              0\n0   0.22              1\n20  0.21              1\n22  0.40              1\n5   0.56              1\n25  0.54              1\n1   0.25              0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>affordibility</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16</th>\n      <td>0.25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.58</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.55</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.46</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.60</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.49</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.28</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.47</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.55</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.62</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.23</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.19</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.45</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.27</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.52</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.22</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.21</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.40</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.56</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.54</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.25</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**At first we will implement a gradient descent, for this we will implement a log loss function**","metadata":{}},{"cell_type":"code","source":"def log_loss(y_true, y_predicted):\n    epsilon = 1e-15\n    y_predicted_new = [max(i,epsilon) for i in y_predicted]\n    y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]\n    y_predicted_new = np.array(y_predicted_new)\n    \n    return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:33:51.813713Z","iopub.execute_input":"2021-05-21T14:33:51.814139Z","iopub.status.idle":"2021-05-21T14:33:51.821261Z","shell.execute_reply.started":"2021-05-21T14:33:51.814101Z","shell.execute_reply":"2021-05-21T14:33:51.819836Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import math\ndef sigmoid_numpy(x):\n    return 1 / (1 + np.exp(-x))\n\nsigmoid_numpy(np.array([12,0,1]))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:33:53.538228Z","iopub.execute_input":"2021-05-21T14:33:53.538657Z","iopub.status.idle":"2021-05-21T14:33:53.547256Z","shell.execute_reply.started":"2021-05-21T14:33:53.538615Z","shell.execute_reply":"2021-05-21T14:33:53.546092Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"array([0.99999386, 0.5       , 0.73105858])"},"metadata":{}}]},{"cell_type":"code","source":"def gradient_descent(age, affordibility, y_true, epochs):\n    #w1,w2, bias\n    w1 = w2 = 1\n    bias = 0\n    rate = 0.5\n    n = len(age)\n    \n    for i in range(epochs):\n        weighted_sum = w1* age + w2 * affordibility + bias \n        y_predicted = sigmoid_numpy(weighted_sum)\n        \n        loss = log_loss(y_true, y_predicted)\n                   \n# derivative function of weights\n\n        w1d = (1/n)*np.dot(np.transpose(age), (y_predicted-y_true))\n        w2d=(1/n)*np.dot(np.transpose(affordibility),(y_predicted - y_true))\n\n        biasd =  np.mean(y_predicted - y_true)\n\n        w1 = w1 - rate * w1d\n        w2 = w2 - rate * w2d\n\n        bias = bias - rate * biasd\n        \n        if i%100==0:\n            print(f'Epoch:{i}, w1:{w1}, w2:{w2}. bias:{bias}, loss:{loss}')\n        \n    return w1, w2, bias\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:33:54.698853Z","iopub.execute_input":"2021-05-21T14:33:54.699277Z","iopub.status.idle":"2021-05-21T14:33:54.709469Z","shell.execute_reply.started":"2021-05-21T14:33:54.699235Z","shell.execute_reply":"2021-05-21T14:33:54.708059Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class myNN:\n    def __init__(self):\n        self.w1 = 1\n        self.w2 = 1\n        self.bias = 0\n    \n    def fit(self,X,y,epochs):\n        self.w1, self.w2, self.bias = self.gradient_descent(X['age'],X['affordibility'],y,epochs)\n    \n    def predict (self, X_test):\n        weighted_sum = self.w1*X_test['age'] + self.w2*X_test['affordibility'] + self.bias\n        return sigmoid_numpy(weighted_sum)\n    \n    def gradient_descent(self, age, affordibility, y_true, epochs):\n        #w1,w2, bias\n        w1 = w2 = 1\n        bias = 0\n        rate = 0.5\n        n = len(age)\n\n        for i in range(epochs):\n            weighted_sum = w1* age + w2 * affordibility + bias \n            y_predicted = sigmoid_numpy(weighted_sum)\n\n            loss = log_loss(y_true, y_predicted)\n\n            # derivative function of weights\n\n            w1d = (1/n)*np.dot(np.transpose(age), (y_predicted-y_true))\n            w2d=(1/n)*np.dot(np.transpose(affordibility),(y_predicted - y_true))\n\n            biasd =  np.mean(y_predicted - y_true)\n\n            w1 = w1 - rate * w1d\n            w2 = w2 - rate * w2d\n\n            bias = bias - rate * biasd\n\n            if i%100==0:\n                print(f'Epoch:{i}, w1:{w1}, w2:{w2}. bias:{bias}, loss:{loss}')\n\n        return w1, w2, bias\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-05-21T15:10:32.375961Z","iopub.execute_input":"2021-05-21T15:10:32.376351Z","iopub.status.idle":"2021-05-21T15:10:32.387616Z","shell.execute_reply.started":"2021-05-21T15:10:32.376318Z","shell.execute_reply":"2021-05-21T15:10:32.386364Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"my_model = myNN()\nmy_model.fit(X_train_scaled, y_train, epochs=1800)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T15:11:32.193758Z","iopub.execute_input":"2021-05-21T15:11:32.194202Z","iopub.status.idle":"2021-05-21T15:11:37.699374Z","shell.execute_reply.started":"2021-05-21T15:11:32.194164Z","shell.execute_reply":"2021-05-21T15:11:37.698116Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch:0, w1:0.9789024800890708, w2:0.9520957400198559. bias:-0.09667115062627897, loss:0.6854368133995636\nEpoch:100, w1:2.1409338756487855, w2:1.2210532891115777. bias:-1.4778451479263979, loss:0.5511370818846864\nEpoch:200, w1:3.3203811158913674, w2:1.318637135486689. bias:-2.053823365424557, loss:0.5162162472418467\nEpoch:300, w1:4.314640466718753, w2:1.3473880051278433. bias:-2.4961864979390214, loss:0.4923845922803831\nEpoch:400, w1:5.149024358640796, w2:1.3698723444964782. bias:-2.8656275421341073, loss:0.47563719113978276\nEpoch:500, w1:5.853809491665046, w2:1.3945783631617954. bias:-3.182112458754181, loss:0.46363213875560877\nEpoch:600, w1:6.45427490497623, w2:1.4211578019630267. bias:-3.4562296699337454, loss:0.45486691321771927\nEpoch:700, w1:6.970181816108681, w2:1.44833468898194. bias:-3.6953586380113355, loss:0.4483597639660555\nEpoch:800, w1:7.416833111659687, w2:1.475139249612155. bias:-3.9051765414859254, loss:0.44345705262092155\nEpoch:900, w1:7.80615009973734, w2:1.5009683653274908. bias:-4.090201107827065, loss:0.43971484511176495\nEpoch:1000, w1:8.1475172119393, w2:1.5254830426280919. bias:-4.254084166859125, loss:0.4368256999806182\nEpoch:1100, w1:8.44840725959282, w2:1.5485159901309535. bias:-4.399809867988306, loss:0.43457276360211167\nEpoch:1200, w1:8.714838861875547, w2:1.5700078302112315. bias:-4.529839777258389, loss:0.4328004721670959\nEpoch:1300, w1:8.951712101029814, w2:1.589965656210052. bias:-4.646222075788326, loss:0.4313954964531977\nEpoch:1400, w1:9.16305687434627, w2:1.6084364773995936. bias:-4.750674807192185, loss:0.43027411392253084\nEpoch:1500, w1:9.352218539812423, w2:1.6254902295469247. bias:-4.84464994423695, loss:0.4293736880504105\nEpoch:1600, w1:9.521998196978858, w2:1.6412089076812142. bias:-4.92938313429656, loss:0.4286468203182739\nEpoch:1700, w1:9.674759840218927, w2:1.655679638892611. bias:-5.005932667776777, loss:0.42805727214671624\n","output_type":"stream"}]},{"cell_type":"code","source":"my_model.predict(X_train_scaled)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T15:12:23.699990Z","iopub.execute_input":"2021-05-21T15:12:23.700360Z","iopub.status.idle":"2021-05-21T15:12:23.710523Z","shell.execute_reply.started":"2021-05-21T15:12:23.700329Z","shell.execute_reply":"2021-05-21T15:12:23.709239Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"16    0.067752\n17    0.907611\n6     0.579717\n27    0.751656\n7     0.692572\n14    0.802470\n11    0.341065\n2     0.769516\n15    0.879793\n8     0.935671\n26    0.240651\n18    0.038775\n23    0.732894\n24    0.817562\n12    0.081247\n3     0.506818\n0     0.223181\n20    0.206634\n22    0.626866\n5     0.889789\n25    0.869025\n1     0.067752\ndtype: float64"},"metadata":{}}]}]}