# -*- coding: utf-8 -*-
"""dummyModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eB4mK3ENNk264gBCgtnG3fUbaoSET2N3
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np 
import pandas as pd 
import seaborn as sns 
import matplotlib.ticker as mtick  
import matplotlib.pyplot as plt
# %matplotlib inline

"""Importing the dataset that I found at online"""

dataset = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')

dataset.head(10)

dataset.shape

dataset.dtypes

"""Getting info of numeric variables"""

dataset.describe()

dataset.info(verbose = True)

missing_values = pd.DataFrame((dataset.isnull().sum())*100/dataset.shape[0]).reset_index()
print(missing_values)

plt.figure(figsize=(15,6))
ax = sns.pointplot('index',0,data=missing_values)
plt.xticks(rotation =90,fontsize =10)
plt.title("Percentage of Missing values")
plt.ylabel("PERCENTAGE")
plt.show()

dataset['Churn'].value_counts()

100*dataset['Churn'].value_counts()/len(dataset['Churn'])

dataset['Churn'].value_counts().plot(kind='pie', figsize=(10, 5))
plt.title("Count of Churn", y=1);

"""Data cleaning part will be started"""

telco_data = dataset.copy()

telco_data.TotalCharges = pd.to_numeric(telco_data.TotalCharges, errors='coerce')

telco_data.TotalCharges

telco_data.isnull().sum()

telco_data.loc[telco_data ['TotalCharges'].isnull() == True]

missing = pd.DataFrame((telco_data.isnull().sum())*100/telco_data.shape[0]).reset_index()
print(missing)

telco_data.dropna(how = 'any', inplace = True)

print(telco_data['tenure'].max())

labels = ["{0} - {1}".format(i, i + 11) for i in range(1, 72, 12)]

telco_data['tenure_group'] = pd.cut(telco_data.tenure, range(1, 80, 12), right=False, labels=labels)

telco_data['tenure_group'].value_counts()

telco_data.drop(columns= ['customerID','tenure'], axis=1, inplace=True)
telco_data.head()

"""Univariate Analysis"""

for i, predictor in enumerate(telco_data.drop(columns=['Churn', 'TotalCharges', 'MonthlyCharges'])):
    plt.figure(i)
    sns.countplot(data=telco_data, x=predictor, hue='Churn')

telco_data['Churn'] = np.where(telco_data.Churn == 'Yes',1,0)

telco_data.head()

telco_data_dummies = pd.get_dummies(telco_data)
telco_data_dummies.head()

sns.lmplot(data=telco_data_dummies, x='MonthlyCharges', y='TotalCharges')

Monthly = sns.kdeplot(telco_data_dummies.MonthlyCharges[(telco_data_dummies["Churn"] == 0) ],
                color="Red", shade = True)
Monthly = sns.kdeplot(telco_data_dummies.MonthlyCharges[(telco_data_dummies["Churn"] == 1) ],
                ax =Monthly, color="Blue", shade= True)
Monthly.legend(["No Churn","Churn"],loc='upper right')
Monthly.set_ylabel('Density')
Monthly.set_xlabel('Monthly Charges')
Monthly.set_title('Monthly charges by churn')

Total = sns.kdeplot(telco_data_dummies.TotalCharges[(telco_data_dummies["Churn"] == 0) ],
                color="Red", shade = True)
Total = sns.kdeplot(telco_data_dummies.TotalCharges[(telco_data_dummies["Churn"] == 1) ],
                ax =Total, color="Blue", shade= True)
Total.legend(["No Churn","Churn"],loc='upper right')
Total.set_ylabel('Density')
Total.set_xlabel('Total Charges')
Total.set_title('Total charges by churn')

plt.figure(figsize=(20,8))
telco_data_dummies.corr()['Churn'].sort_values(ascending = False).plot(kind='bar')

plt.figure(figsize=(12,12))
sns.heatmap(telco_data_dummies.corr(), cmap="Paired")

new_df1_target0=telco_data.loc[telco_data["Churn"]==0]
new_df1_target1=telco_data.loc[telco_data["Churn"]==1]

"""Bivariate Analysis"""

def uniplot(df,col,title,hue =None):
    
    sns.set_style('darkgrid')
    sns.set_context('talk')
    plt.rcParams["axes.labelsize"] = 12
    plt.rcParams['axes.titlesize'] = 12
    plt.rcParams['axes.titlepad'] = 20
    
    
    temp = pd.Series(data = hue)
    fig, ax = plt.subplots()
    width = len(df[col].unique()) + 5 + 3*len(temp.unique())
    fig.set_size_inches(width , 6)
    plt.xticks(rotation=45)
    plt.yscale('log')
    plt.title(title)
    ax = sns.countplot(data = df, x= col, order=df[col].value_counts().index,hue = hue,palette='bright') 
        
    plt.show()

uniplot(new_df1_target1,col='Partner',title='Distribution of Gender for Churned Customers',hue='gender')

uniplot(new_df1_target0,col='Partner',title='Distribution of Gender for Non Churned Customers',hue='gender')

uniplot(new_df1_target1,col='PaymentMethod',title='Distribution of PaymentMethod for Churned Customers',hue='gender')

uniplot(new_df1_target1,col='Contract',title='Distribution of Contract for Churned Customers',hue='gender')

uniplot(new_df1_target1,col='TechSupport',title='Distribution of TechSupport for Churned Customers',hue='gender')

uniplot(new_df1_target1,col='SeniorCitizen',title='Distribution of SeniorCitizen for Churned Customers',hue='gender')

"""Created A new Csv file"""

telco_data_dummies.to_csv('telco_churn.csv')

import pandas as pd
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import recall_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from imblearn.combine import SMOTEENN

df = pd.read_csv('telco_churn.csv')

df.head()

df = df.drop('Unnamed: 0', axis=1)

df.shape

"""X and Y variable"""

x = df.drop('Churn', axis=1)
y = df['Churn']

x

y

"""Dividing training and test data. This data will be used for DecisionTree classifier and Random Forrest Classifier"""

x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2)

"""###Decision Tree Classifier###"""

model_dt = DecisionTreeClassifier(criterion='gini', random_state=100, max_depth=6, min_samples_leaf=8)

#fitting the traning data
model_dt.fit(x_train, y_train)

y_pred=model_dt.predict(x_test)

y_pred

model_dt.score(x_test,y_test)

print(classification_report(y_test, y_pred, labels=[0,1]))

"""Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier

model_rf=RandomForestClassifier(n_estimators=100, criterion='gini', random_state = 100,max_depth=6, min_samples_leaf=8)

model_rf.fit(x_train,y_train)

RandomForestClassifier(max_depth=6, min_samples_leaf=8, random_state=100)

y_pred=model_rf.predict(x_test)

model_rf.score(x_test,y_test)

print(classification_report(y_test, y_pred, labels=[0,1]))

"""SMOTEENN (UpSampling + ENN)"""

sm = SMOTEENN()
X_resampled, y_resampled = sm.fit_sample(x,y)

xr_train,xr_test,yr_train,yr_test=train_test_split(X_resampled, y_resampled,test_size=0.2)

model_dt_smote=DecisionTreeClassifier(criterion = "gini",random_state = 100,max_depth=6, min_samples_leaf=8)

model_dt_smote.fit(xr_train,yr_train)
yr_predict = model_dt_smote.predict(xr_test)
model_score_r = model_dt_smote.score(xr_test, yr_test)
print(model_score_r)
print(metrics.classification_report(yr_test, yr_predict))

print(metrics.confusion_matrix(yr_test, yr_predict))

model_rf_smote=RandomForestClassifier(n_estimators=100, criterion='gini', random_state = 100,max_depth=6, min_samples_leaf=8)

model_rf_smote.fit(xr_train,yr_train)

yr_predict1 = model_rf_smote.predict(xr_test)

model_score_r1 = model_rf_smote.score(xr_test, yr_test)

print(model_score_r1)
print(metrics.classification_report(yr_test, yr_predict1))

print(metrics.confusion_matrix(yr_test, yr_predict1))